# Logging & Analytics Service — Caching Strategy

Caching в контуре наблюдаемости нужен, но его надо применять аккуратно, чтобы не нарушать свежесть данных для инцидент-менеджмента.

---

## 1. Что можно кешировать

### 1.1. Агрегированные отчёты и дашборды

- Дневные/часовые агрегаты логов и аналитики:
  - количество квестов,
  - количество покупок ваучеров,
  - количество регистраций и т.п.
- Кеширование в:
  - ClickHouse materialized views,
  - Redis / in-memory caches для быстрых дашбордов.

### 1.2. Часто используемые запросы

- Предопределённые панели Grafana,
- типовые Kibana/ClickHouse запросы,
- предрасчитанные KPI (например, «кол-во quest_completed за вчера»).

---

## 2. Что нельзя кешировать

- свежие сырые логи:
  - нужны в реальном времени для отладки;
- трассировки:
  - особенно в момент инцидента важна актуальность;
- security-логи:
  - любые задержки в их обработке/просмотре нежелательны.

---

## 3. Баланс между свежестью и скоростью

Подход:

- для инцидентов:
  - опираться на «живые» данные (последние 5–15 минут),
  - без дополнительного кеша;
- для аналитики:
  - использовать агрегированные данные,
  - обновление раз в N минут/час.

---

## 4. Взаимодействие с внешними кешами

Если фронтенд/админка использует API Logging & Analytics для построения панелей:

- можно кешировать ответы API (на уровне BFF):
  - на 30–120 секунд,
  - только для тяжёлых запросов (например, большой временной диапазон по аналитике).

Но сами хранилища (Prometheus, Jaeger, ClickHouse) остаются «источником истины».
